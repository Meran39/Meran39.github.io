// ===============================
// src/services/llm.ts
// ===============================
import { LLMConfig, ActionResponse, MoodType, LLMProvider } from '../types';
import { CostOptimizer } from './costOptimizer';
import { HfInference } from '@huggingface/inference'; // この行を追加

// API呼び出し設定の型定義 (これはもう不要になりますが、一旦残します)
interface ApiConfig {
  url: () => string;
  headers: (apiKey: string) => Record<string, string>;
  body: (
    prompt: string,
    config: LLMConfig,
    type: 'action' | 'summarize'
  ) => Record<string, unknown>;
  parseResponse: (data: unknown, type: 'action' | 'summarize') => Partial<ActionResponse>;
}

// 各プロバイダーのAPI設定 (Hugging Faceの部分は変更します)
const apiConfigs: Record<LLMProvider, ApiConfig> = {
  huggingface: {
    url: () => ``, // これはもう使われません
    headers: (apiKey) => ({
      Authorization: `Bearer ${apiKey}`,
      'Content-Type': 'application/json',
    }),
    body: (prompt, config) => ({
      inputs: prompt,
      parameters: {
        max_new_tokens: config.maxTokens,
        temperature: config.temperature,
        return_full_text: false,
      },
    }),
    parseResponse: (data, type) => {
      // parseResponseはHugging Face Inferenceライブラリのレスポンス形式に合わせて調整が必要
      // ここは後で調整します
      const text = Array.isArray(data)
        ? (data as { generated_text: string }[])[0]?.generated_text
        : (data as { generated_text: string }).generated_text;
      console.log('Hugging Face Raw Response Text:', text);
      if (type === 'summarize') {
        return { action: text || '' };
      }
      try {
        const parsed = JSON.parse(text);
        console.log('Hugging Face Parsed Response:', parsed);
        return {
          plan: parsed.plan,
          action: parsed.action,
          reasoning: 'Generated by Hugging Face',
          mood: parsed.mood,
          energy: parsed.energy,
          happiness: parsed.happiness,
          hunger: parsed.hunger,
        };
      } catch {
        return { action: text || '', reasoning: 'Generated by Hugging Face' };
      }
    },
  },
  // openai, anthropic の設定はそのまま
  openai: {
    url: () => 'https://api.openai.com/v1/chat/completions',
    headers: (apiKey) => ({
      Authorization: `Bearer ${apiKey}`,
      'Content-Type': 'application/json',
    }),
    body: (prompt, config, type) => {
      const messages: { role: string; content: string }[] = [];
      if (type === 'action') {
        messages.push({
          role: 'system',
          content: '次の形式で応答してください: {"plan": "短期計画", "action": "具体的な行動"}',
        });
      } else if (type === 'summarize') {
        messages.push({
          role: 'system',
          content: 'あなたは与えられたテキストを要約するAIアシスタントです。',
        });
      }
      messages.push({ role: 'user', content: prompt });
      return {
        model: config.model,
        messages: messages,
        max_tokens: config.maxTokens,
        temperature: config.temperature,
        response_format: { type: 'json_object' },
      };
    },
    parseResponse: (data, type) => {
      const content = (data as { choices: { message: { content: string } }[] }).choices[0]?.message
        ?.content;
      if (type === 'summarize') {
        return { action: content || '' };
      }
      try {
        console.log('OpenAI Raw Response Content:', content);
        const parsed = JSON.parse(content);
        console.log('OpenAI Parsed Response:', parsed);
        return {
          plan: parsed.plan,
          action: parsed.action,
          reasoning: 'Generated by OpenAI',
          mood: parsed.mood,
          energy: parsed.energy,
          happiness: parsed.happiness,
          hunger: parsed.hunger,
        };
      } catch {
        return { action: content || '', reasoning: 'Generated by OpenAI' };
      }
    },
  },
  anthropic: {
    url: () => 'https://api.anthropic.com/v1/messages',
    headers: (apiKey) => ({
      'x-api-key': apiKey,
      'Content-Type': 'application/json',
      'anthropic-version': '2023-06-01',
    }),
    body: (prompt, config, type) => {
      const messages: { role: string; content: string }[] = [];
      if (type === 'action') {
        messages.push({
          role: 'system',
          content:
            '次のJSON形式で応答してください: {"plan": "短期計画", "action": "具体的な行動", "mood": "気分", "energy": 0-100}',
        });
      } else if (type === 'summarize') {
        messages.push({
          role: 'system',
          content: 'あなたは与えられたテキストを要約するAIアシスタントです。',
        });
      }
      messages.push({ role: 'user', content: prompt });
      return {
        model: config.model,
        max_tokens: config.maxTokens,
        temperature: config.temperature,
        messages: messages,
      };
    },
    parseResponse: (data, type) => {
      const text = (data as { content: { text: string }[] }).content[0]?.text;
      console.log('Anthropic Raw Response Text:', text);
      if (type === 'summarize') {
        return { action: text || '' };
      }
      try {
        const parsed = JSON.parse(text);
        console.log('Anthropic Parsed Response:', parsed);
        return {
          plan: parsed.plan,
          action: parsed.action,
          reasoning: 'Generated by Anthropic',
          mood: parsed.mood,
          energy: parsed.energy,
          happiness: parsed.happiness,
          hunger: parsed.hunger,
        };
      } catch {
        return { action: text || '', reasoning: 'Generated by Anthropic' };
      }
    },
  },
  ollama: {
    url: () => `http://localhost:11434/api/generate`, // 引数なしにする
    headers: () => ({
      'Content-Type': 'application/json',
    }),
    body: (prompt, config, type) => {
      const systemPrompt =
        type === 'action'
          ? 'あなたは仮想住民の行動を決定するAIです。会話的なテキストや前置きを含めず、JSONオブジェクトのみを出力してください。JSONは {"plan": "短期計画", "action": "具体的な行動", "mood": "気分", "energy": 0-100} の形式である必要があります。'
          : 'あなたは与えられたテキストを簡潔に要約するAIアシスタントです。会話的なテキストや前置きを含めず、要約のみを返してください。';
      const userPrompt =
        type === 'action'
          ? prompt
          : `以下のテキストを簡潔に要約してください:\n\n${prompt}\n\n要約:`;

      return {
        model: config.model,
        prompt: userPrompt,
        system: systemPrompt, // システムプロンプトを追加
        options: {
          temperature: config.temperature,
          num_predict: config.maxTokens,
        },
        format: 'json', // JSON形式を強制
        stream: false,
      };
    },
    parseResponse: (data, type) => {
      const rawText = (data as { response: string }).response;
      console.log('Ollama Raw Response Text:', rawText);
      if (type === 'summarize') {
        return { action: rawText || '' };
      }
      try {
        // JSON部分を抽出する正規表現
        const jsonMatch = rawText.match(/\{.*\}/s);
        if (jsonMatch) {
          const jsonString = jsonMatch[0];
          const parsed = JSON.parse(jsonString);
          console.log('Ollama Parsed Response:', parsed);
          return {
            plan: parsed.plan,
            action: parsed.action,
            reasoning: 'Generated by Ollama',
            mood: parsed.mood,
            energy: parsed.energy,
            happiness: parsed.happiness,
            hunger: parsed.hunger,
          };
        } else {
          console.warn('Ollama response did not contain a valid JSON object:', rawText);
          return { action: rawText || '', reasoning: 'Generated by Ollama (JSON parse failed)' };
        }
      } catch (e) {
        console.error('Error parsing Ollama JSON response:', e, rawText);
        return { action: rawText || '', reasoning: 'Generated by Ollama (JSON parse error)' };
      }
    },
  },
};

export class LLMService {
  private config: LLMConfig;
  private costOptimizer: CostOptimizer;
  public totalTokensUsed: number = 0;
  public totalCost: number = 0;
  private hf: HfInference | null = null; // この行を追加

  constructor(config: LLMConfig, costOptimizer: CostOptimizer) {
    this.config = config;
    this.costOptimizer = costOptimizer;
    console.log('LLMService initialized with API Key:', this.config.apiKey ? 'Set' : 'Not Set');
    if (this.config.provider === 'huggingface') {
      this.hf = new HfInference(this.config.apiKey, { endpointUrl: this.config.baseUrl });
    }
  }

  private async callApi(
    prompt: string,
    config: LLMConfig,
    type: 'action' | 'summarize'
  ): Promise<ActionResponse> {
    console.log('callApi called with provider:', config.provider);

    if (config.provider === 'huggingface' && this.hf) {
      try {
        console.log('Attempting to fetch from Hugging Face Inference API using SDK...');
        const result = await this.hf.textGeneration({
          model: config.model,
          inputs: prompt,
          parameters: {
            max_new_tokens: config.maxTokens,
            temperature: config.temperature,
            return_full_text: false,
          },
        });
        console.log('Hugging Face Inference API SDK result:', result);

        // SDKのレスポンス形式に合わせてparseResponseを調整
        const text = result.generated_text;
        if (type === 'summarize') {
          return { action: text || '' };
        }
        try {
          const parsed = JSON.parse(text);
          return {
            plan: parsed.plan,
            action: parsed.action,
            reasoning: 'Generated by Hugging Face SDK',
            mood: parsed.mood,
            energy: parsed.energy,
          };
        } catch {
          return { action: text || '', reasoning: 'Generated by Hugging Face SDK' };
        }
      } catch (error) {
        console.error('Hugging Face Inference API SDK Error:', error);
        throw new Error(
          `Hugging Face SDK error: ${error instanceof Error ? error.message : 'Unknown error'}`
        );
      }
    } else {
      // OpenAI, Anthropic, Hugging Face SDKが初期化されていない場合の既存ロジック
      const apiConfig = apiConfigs[config.provider];
      if (!apiConfig) {
        throw new Error(`Unsupported LLM provider: ${config.provider}`);
      }

      const url = apiConfig.url(); // ✅ 修正済
      const headers = apiConfig.headers(config.apiKey);
      const body = JSON.stringify(apiConfig.body(prompt, config, type)); // ✅ 修正済

      console.log('Attempting to fetch from URL:', url);
      const response = await fetch(url, {
        method: 'POST',
        headers: headers,
        body: body,
        mode: 'cors',
      });

      console.log('Fetch call completed. Response status:', response.status);

      if (!response.ok) {
        console.error(
          `Fetch response not OK. Status: ${response.status}, StatusText: ${response.statusText}`
        );
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const data = await response.json();
      console.log('Received data from API:', data);
      const parsedResponse = apiConfig.parseResponse(data, type);

      // トークン使用量とコストを計算・更新
      const inputText = prompt;
      const outputText = parsedResponse.action || '';
      const inputTokens = inputText.length; // 簡単な文字数カウント
      const outputTokens = outputText.length;
      const tokensUsed = inputTokens + outputTokens;
      const cost = this.costOptimizer.estimateCost(
        inputTokens,
        outputTokens,
        config.model,
        config.provider
      );
      this.totalTokensUsed += tokensUsed;
      this.totalCost += cost;

      // 完全なActionResponseを構築
      return {
        plan: parsedResponse.plan,
        action:
          type === 'summarize'
            ? parsedResponse.action!
            : this.extractAction(parsedResponse.action!),
        reasoning: parsedResponse.reasoning || `Generated by ${config.provider}`,
        mood: parsedResponse.mood || this.extractMood(parsedResponse.action!),
        energy: parsedResponse.energy || Math.floor(Math.random() * 20) + 80,
        happiness: parsedResponse.happiness || Math.floor(Math.random() * 20) + 80,
        hunger: parsedResponse.hunger || Math.floor(Math.random() * 20) + 80,
      };
    }
  }

  private extractAction(text: string): string {
    const actionPatterns = [
      /"action"\s*:\s*"(.*?)"/,
      /行動[：:]\s*(.+)/,
      /今から\s*(.+)/,
      /(.+?)(?:\n|$)/, // Corrected to match the original_old_string's regex
    ];

    for (const pattern of actionPatterns) {
      const match = text.match(pattern);
      if (match) {
        return match[1].trim().slice(0, 50);
      }
    }
    return text.slice(0, 50) || '考え中...';
  }

  private extractMood(text: string): MoodType {
    const moodKeywords = {
      happy: ['楽しい', '嬉しい', '幸せ', '明るい'],
      excited: ['わくわく', '興奮', 'ドキドキ', '期待'],
      thoughtful: ['考える', '思考', '悩む', '検討'],
      content: ['満足', '充実', '安心', '平穏'],
      creative: ['創造', '作る', '描く', '書く'],
      social: ['話す', '会う', '交流', '友達'],
      tired: ['疲れ', '休む', '眠い', 'リラックス'],
    };

    for (const [mood, keywords] of Object.entries(moodKeywords)) {
      if (keywords.some((keyword) => text.includes(keyword))) {
        return mood as MoodType;
      }
    }
    return 'neutral';
  }

  private getFallbackResponse(): ActionResponse {
    const fallbackActions = [
      'コーヒーを淹れて香りを楽しむ',
      '窓辺で植物に水をあげる',
      '散歩をしながら空を眺める',
      '読みかけの本を続きから読む',
      '音楽を聴きながらリラックス',
      '新しいレシピを考える',
      '日記に今日の今日の出来事を書く',
      '友人にメッセージを送る',
    ];

    return {
      action: fallbackActions[Math.floor(Math.random() * fallbackActions.length)],
      reasoning: 'Fallback response',
      mood: 'neutral',
      energy: 75,
    };
  }

  async generateAction(prompt: string): Promise<ActionResponse> {
    const optimalConfig = this.costOptimizer.selectOptimalModel(
      {
        huggingface: this.config,
        openai: this.config,
        anthropic: this.config,
        ollama: this.config, // Ollamaの設定も追加
      },
      this.config.provider
    );

    try {
      return await this.callApi(prompt, optimalConfig, 'action');
    } catch (error) {
      console.error('LLM API Error:', error);
      return this.getFallbackResponse();
    }
  }

  async summarizeText(text: string): Promise<string> {
    const prompt = `以下のテキストを簡潔に要約してください:\n\n${text}\n\n要約:`;
    const optimalConfig = this.costOptimizer.selectOptimalModel(
      {
        huggingface: this.config,
        openai: this.config,
        anthropic: this.config,
        ollama: this.config, // Ollamaの設定も追加
      },
      this.config.provider
    );

    try {
      const response = await this.callApi(prompt, optimalConfig, 'summarize');
      return response.action;
    } catch (error) {
      console.error('LLM Summarization Error:', error);
      return '要約に失敗しました。';
    }
  }
}
